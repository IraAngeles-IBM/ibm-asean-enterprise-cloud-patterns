{"componentChunkName":"component---src-pages-iac-resources-services-index-mdx","path":"/iac-resources/services/","result":{"pageContext":{"frontmatter":{"title":"IaC for Cloud Databases and Service Instances","description":"Use IaC to work with managed Cloud Databases and Service Instances","keywords":"terraform,ibm cloud,db,dba"},"relativePagePath":"/iac-resources/services/index.mdx","titleType":"page","MdxNode":{"id":"49fe9da3-836b-56dc-8764-fb9d24bcb544","children":[],"parent":"d27385b2-0908-5be9-ba3e-fd7ea43b1074","internal":{"content":"---\ntitle: IaC for Cloud Databases and Service Instances\ndescription: Use IaC to work with managed Cloud Databases and Service Instances\nkeywords: 'terraform,ibm cloud,db,dba'\n---\n\n<!--\n\nThe pattern to document the resources is like follow:\n- Introduce the resource with an example\n- List all or the most important input parameters\n- If will be used, list the most important output parameters\n- Provide instructions to get the value of the input parameters, either using `ibmcloud`, API or the Web console.\n- If needed, instructions to execute the code either with Terraform or Schematics\n\n-->\n\n<PageDescription>\n\nUse IaC to work with managed Cloud Databases and Service Instances\n\n</PageDescription>\n\nMost of the applications requires a database or service. This page explains how to use the `ibm_database` and `ibm_resource_instance` resources to create different type of databases or services. We will use the API movies demo application to demonstrate the use of a provisioned MongoDB database. The following diagram shows the architecture we will build in this page.\n\n![Architecture](./images/IaC-Cloud_Services_Resources.png \"Cloud Database Resources Architecture\")\n\nThe code to build these resources can be downloaded from the GitHub repository https://github.com/IBM/cloud-enterprise-examples/ in the directory [08_cloud-services](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services).\n\n<AnchorLinks small>\n  <AnchorLink>Cloud Database Services</AnchorLink>\n  <AnchorLink>MongoDB</AnchorLink>\n  <AnchorLink>Access the database with MongoDB Compass</AnchorLink>\n  <AnchorLink>Access to the MongoDB database with Python</AnchorLink>\n  <AnchorLink>PostgreSQL</AnchorLink>\n  <AnchorLink>Access to the PostgreSQL database with NodeJS</AnchorLink>\n  <AnchorLink>Service Instances</AnchorLink>\n  <AnchorLink>Message Queue</AnchorLink>\n  <AnchorLink>Final Terraform code</AnchorLink>\n  <AnchorLink>Clean up</AnchorLink>\n</AnchorLinks>\n\nAs you look at the PostgreSQL & MongoDB code, you will notice the similarity.  In fact, except for the `service` type, they are identical.  This is because the scripts are using Resource Management Resources and managing resources for the IBM Cloud database services.  You can find out more about it [here](https://cloud.ibm.com/docs/terraform?topic=terraform-resource-mgmt-resources#resource-instance).\n\n## Cloud Database Services\n\n[IBM Cloud Database](https://www.ibm.com/cloud/databases) offers many database options, with each one being useful for a particular use-case. The IBM Cloud Provider supports creation of [Cloud Databases resources](https://cloud.ibm.com/docs/terraform?topic=terraform-databases-resources) of several different flavors including: **etcd**, **PostgreSQL**, **Redis**, **ElasticSearch**, **MongoDB** and messaging with **RabbitMQ**.\n\nTo create a Cloud Database we use the Terraform resource `ibm_database`. No matter what database flavor is provisioned, we always provide the same input parameters and get the same output parameters. The DB flavor will only affect the values of these parameters.\n\nThe following table lists the most relevant input parameters for the `ibm_database` resource.\n\n| Input parameter | Description |\n|---|---|\n| `name` | name to identify the _database instance_.  The name must not include spaces. Notice that this is not the name as the database |\n| `plan` | service plan that you choose for your instance. The supported values is `standard` |\n| `location` | location to deploy your instance, it must match the region parameter that you specify in the provider block |\n| `tags` | optional list of tags to add to your instance |\n| `service` | type of Cloud Databases to create, the following services are accepted: `databases-for-etcd`, `databases-for-postgresql`, `databases-for-mongodb`, `databases-for-redis`, `databases-for-elasticsearch` and `messages-for-rabbitmq` |\n| `adminpassword`\t| password for the database administrator. If not specified, additional users must be specified in a user block |\n| `members_memory_allocation_mb` | amount of memory in megabytes for the database, split across all members |\n| `members_disk_allocation_mb` | amount of disk space for the database, split across all members |\n| `members_cpu_allocation_count` | allocates the number of specified dedicated cores to your deployment |\n| `backup_id` | CRN of a backup resource to restore from. The backup must have been created by a database deployment with the same service ID. The backup is loaded after provisioning and the new deployment starts up that uses that data. A backup CRN is in the format `crn:v1:<…>:backup:`. If omitted, the database is provisioned empty |\n| `key_protect_key` | CRN of a Key Protect root key that you want to use for disk encryption. A key protect CRN is in the format `crn:v1:<…>:key:` |\n| `key_protect_instance` | CRN of a Key Protect instance that you want to use for disk encryption. A key protect CRN is in the format `crn:v1:<…>::` |\n| `service_endpoints` | to enable the `public`, `private`, or both `public-and-private` service endpoints. The default is `public` |\n| `users` | list of users to create on the database. Multiple blocks are allowed |\n| `users.name` | name of the user ID to add to the database instance. The user ID must be between 5 and 32 characters |\n| `users.password` | password for the user ID. The password must be between 10 and 32 characters |\n| `whitelist` | list of IP addresses to allow access for the database. Multiple blocks are allowed. If not specified access from any IP is allowed |\n| `whitelist.address` | The IP address or range of database client addresses to be whitelisted in CIDR format. Example: `172.168.1.2/32` |\n\nThe list of output parameters is like follows:\n\n| Input parameter | Description |\n|---|---|\n| `id` | CRN of the database instance |\n| `status` | status of the instance |\n| `adminuser` | user ID of the database administrator. Example: `admin` or `root` |\n| `version` | database version |\n| `connectionstrings` | list of [connection strings](https://cloud.ibm.com/docs/services/databases-for-postgresql?topic=databases-for-postgresql-connection-strings) for the database for each user ID. The results are returned in pairs of the userid and string: `connectionstrings.1.name = admin connectionstrings.1.string = postgres://admin:$PASSWORD@79226bd4-4076-4873-b5ce-b1dba48ff8c4.b8a5e798d2d04f2e860e54e5d042c915.databases.appdomain.cloud:32554/ibmclouddb?sslmode=verify-full` Individual string parameters can be retrieved using Terraform variables and outputs `connectionstrings.x.hosts.x.port` and `connectionstrings.x.hosts.x.host` |\n\nThe following sections will explain how to create a simple Cloud Database with **MongoDB** and **PostgreSQL**. To view an example of **etcd**, refer to the section [Setup Terraform Remote State using etcd as backend](/iac/getting-started-terraform/remote-state).\n\n## MongoDB\n\nThis is a simple example to create a single instance running MongoDB. The final code can be found in the directory [08_cloud-services/simple_mongodb](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services/simple_mongodb) of the GitHub repository with all the code patterns. A full example with application setup on VSI compute can be found in the [08_cloud-services](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services) and is discussed towards the end of this article.\n\nTo create a MongoDB Cloud Database use the service `databases-for-mongodb`. Create a file to store the database definition (i.e. `db.tf`) with a code similar to this one:\n\n```hcl path=db.tf\nvariable \"db_admin_password\" {}\n\nresource \"ibm_database\" \"db_instance\" {\n  name              = \"sampledb\"\n  plan              = \"standard\"\n  location          = \"us-south\"\n  service           = \"databases-for-mongodb\"\n  resource_group_id = data.ibm_resource_group.group.id\n\n  adminpassword                = var.db_admin_password\n  members_memory_allocation_mb = \"3072\"\n  members_disk_allocation_mb   = \"61440\"\n}\n```\n\nA simple `main.tf` code to use the previous database would be like so:\n\n```hcl path=main.tf\nprovider \"ibm\" {\n  region     = \"us-south\"\n  generation = 2\n}\n\ndata \"ibm_resource_group\" \"group\" {\n  name = \"Default\"\n}\n```\n\nTo view some important output parameters of the provisioned database create the `output.tf` file with these output variables:\n\n```hcl path=output.tf\noutput \"db_connection_composed\" {\n  value = ibm_database.db_instance.connectionstrings.0.composed\n}\noutput \"db_connection_certbase64\" {\n  value = ibm_database.db_instance.connectionstrings.0.certbase64\n}\noutput \"db_admin_password\" {\n  value = var.db_admin_password\n}\n```\n\nIf you need more parameters, add the following output variables to get all the parameters, then add variables with the values of the parameters of the `connectionstrings` or `db_instance` JSON objects.\n\n```hcl\noutput \"db_connection_string\" {\n  value = ibm_database.db_instance.connectionstrings.0\n}\noutput \"instance\" {\n  value = ibm_database.db_instance\n}\n```\n\nTo define the value of the admin password variable export the variable `TF_VAR_db_admin_password` with a password with 10-32 characters or use the following command to generate a random password. The password will be used by the URI in the variable `PASSWORD`, so we are exporting both.\n\n```bash\nexport PASSWORD=$(LC_CTYPE=C tr -dc 'a-zA-Z0-9' < /dev/urandom | head -c 32)\nexport TF_VAR_db_admin_password=$PASSWORD\n```\n\nTo create the database just execute the following terraform commands:\n\n```bash\nterraform init\nterraform plan\nterraform apply\n```\n\nYou'll see the output of the last command with the connection string URI with the variable `db_connection_composed` and the CA certificate encoded with base64 in the variable `db_connection_certbase64`. To get the output varibles again use the command `terraform output`.\n\nYou'll need to save the output variables into environment variables and the certificate to a file executing these commands. In order to interpolate the `PASSWORD` variable into the `APP_MONGODB_URI` variable you have to use the `eval` command like so.\n\n```bash\nterraform output db_connection_certbase64 | base64 --decode > db_ca.crt\nexport PASSWORD=$(terraform output db_admin_password)\nexport APP_MONGODB_URI=$(eval 'echo \"'$(terraform output db_connection_composed)'\"')\necho $APP_MONGODB_URI\n```\n\n<!--\nThe database name in the URI is `ibmclouddb`, assumig the DB name is `demodb` let's use the `sed` command to change it, like so:\n\n```bash\nexport DB_NAME=demodb\nexport APP_MONGODB_URI=$(echo $APP_MONGODB_URI | sed 's|/ibmclouddb?|/$DB_NAME?|')\necho $APP_MONGODB_URI\n```\n-->\n\nAll you need to conect to the database is the conection URI, from the environment variable `APP_MONGODB_URI`, and the CA Certificate, stored in the file `./db_ca.crt`.\n\n## Access the database with MongoDB Compass\n\nLet's use the client MongoDB Compass to access the new provisioned database. Download and install the [MongoDB Compass](https://www.mongodb.com/try/download/compass) application for your platform. Alternatively you can use the `brew` command on Mac OS X to install it.\n\n```bash\nbrew cask install mongodb-compass\n```\n\nOpen MongoDB Compass and you'll see the new connection screen. Copy and paste the connection URI from the environment variable `APP_MONGODB_URI` in the **Paste your connection string** field.\n\n![](./images/mongodb_compass_1.png)\n\nClick on **Fill in connection fields individually**, then select the **More Options** tab. Select **Server Validation** in the **SSL** field, then select the `db_ca.crt` file in the **Certificate Authority** field.\n\n![](./images/mongodb_compass_2.png)\n\nCreate a database clicking on the **CREATE DATABASE** button. Name the database `demodb` and the collection `users`.\n\n![](./images/mongodb_compass_3.png)\n\nClick on the **demodb** database, click on the **users** collection, then on ADD DATA > Insert Document to add any data you want, like the following example:\n\n![](./images/mongodb_compass_4.png)\n\n```json\n[\n  {\n    \"_id\": \"5ee428b13265d9083baa0259\",\n    \"index\": 0,\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 21,\n    \"name\": \"Dale Duffy\",\n    \"gender\": \"male\",\n    \"email\": \"daleduffy@dognosis.com\"\n  },\n  {\n    \"_id\": \"5ee428b19eeb7916a4943a64\",\n    \"index\": 1,\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 36,\n    \"name\": \"Price West\",\n    \"gender\": \"male\",\n    \"email\": \"pricewest@dognosis.com\"\n  },\n  {\n    \"_id\": \"5ee428b198517601184ee994\",\n    \"index\": 2,\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 29,\n    \"name\": \"Arline Gordon\",\n    \"gender\": \"female\",\n    \"email\": \"arlinegordon@dognosis.com\"\n  },\n  {\n    \"_id\": \"5ee428b1cd9893fad62cf901\",\n    \"index\": 3,\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 37,\n    \"name\": \"Mathis Gould\",\n    \"gender\": \"male\",\n    \"email\": \"mathisgould@dognosis.com\"\n  },\n  {\n    \"_id\": \"5ee428b19e46e16ef1284030\",\n    \"index\": 4,\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 30,\n    \"name\": \"Rosemarie Morton\",\n    \"gender\": \"female\",\n    \"email\": \"rosemariemorton@dognosis.com\"\n  }\n]\n```\n\nThere is more information about how to use MongoDB Compass [with the IBM Cloud Database](https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-getting-started) or about how to use [MongoDB Compass](https://docs.mongodb.com/compass/current/) in general.\n\n## Access to the MongoDB database with Python\n\nFor simplicity let's create this code in Python to use the conection string and connect to the database. A similar code can be made in any other programming language.\n\nIn this example we'll use the [pymongo](https://pypi.org/project/pymongo/) package and a JSON file with mock data to import into the database. All the code is located in the directory [08_cloud-services/simple_mongodb](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services/simple_mongodb) of the GitHub repository with all the code patterns.\n\nThe `pymongo` package requires the connection URI, obtained from the environment variable `APP_MONGODB_URI` and the CA certificate from the file `db_ca.crt`, like so.\n\n```python\nfrom pymongo import MongoClient\nimport os\n\nmongodb_uri = os.environ.get('APP_MONGODB_URI')\n\nclient = MongoClient(mongodb_uri,\n                     ssl=True,\n                     ssl_ca_certs=\"./db_ca.crt\")\n```\n\nThe rest of the application is a sample code to insert many documents or just one, to find documents and query the database. Similar sample code can be found in the pymongo [documentation](https://pypi.org/project/pymongo/) or in this [tutorial](https://www.w3schools.com/python/python_mongodb_getstarted.asp). The entire code is shown below and also can be downloaded from [here](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services/simple_mongodb/app.py).\n\n```python path=app.py\nfrom pymongo import MongoClient\nimport json\nimport os\n\nmongodb_uri = os.environ.get('APP_MONGODB_URI')\n\nclient = MongoClient(mongodb_uri,\n                     ssl=True,\n                     ssl_ca_certs=\"./db_ca.crt\")\n\ndbnames = client.list_database_names()\n\ndb = client['demodb']\nbooks = db['books']\n\nif not books.find_one():\n    with open('./db.json') as f:\n        data = json.load(f)\n    books.insert_many(data['books'])\n\nnew_book = {\n    \"isbn\": \"9781449325862\",\n    \"title\": \"Git Pocket Guide\",\n    \"subtitle\": \"A Working Introduction\",\n    \"author\": \"Richard E. Silverman\",\n    \"published\": \"2013-08-02T00:00:00.000Z\",\n    \"publisher\": \"O'Reilly Media\",\n    \"pages\": 234,\n    \"description\": \"This pocket guide is the perfect on-the-job companion to Git, the distributed version control system. It provides a compact, readable introduction to Git for new users, as well as a reference to common commands and procedures for those of you with Git experience.\",\n    \"website\": \"http://chimera.labs.oreilly.com/books/1230000000561/index.html\"\n}\n\nif books.count_documents({\"isbn\": new_book['isbn']}) == 0:\n    book = books.insert_one(new_book)\n    print(\"The new book has been inserted. ID = \", book.inserted_id)\n\nprint(\"Books:\")\nfor book in books.find({}, {\"title\": 1}):\n    print(\"\\t\", book)\n\nquery = {\"publisher\": \"O'Reilly Media\"}\nprint(\"O'Reilly Media's Books:\")\nfor book in books.find(query, {\"title\": 1, \"publisher\": 1}):\n    print(\"\\t\", book)\n\nclient.close()\n```\n\n## PostgreSQL\n\nThis is another simple example to create a single instance running PostgreSQL. The final code can be found in the directory [08_cloud-services/simple_postgresql](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services/simple_postgresql) of the GitHub repository with all the code patterns.\n\nTo create a PostgreSQL Cloud Database use the service `databases-for-postgresql`. Create a file to store the database definition (i.e. `db.tf`) with a code similar to this one:\n\n```hcl path=db.tf\nresource \"ibm_database\" \"db_instance\" {\n  name              = \"sampledb\"\n  plan              = \"standard\"\n  location          = \"us-south\"\n  service           = \"databases-for-postgresql\"\n  resource_group_id = data.ibm_resource_group.group.id\n\n  adminpassword                = \"P@ssW0rd\"\n  members_memory_allocation_mb = \"3072\"\n  members_disk_allocation_mb   = \"61440\"\n}\n```\n\nA simple `main.tf` code to use the previous database would be like so:\n\n```hcl path=main.tf\nprovider \"ibm\" {\n  region             = \"us-south\"\n  generation         = 2\n}\n\ndata \"ibm_resource_group\" \"group\" {\n  name = \"Default\"\n}\n```\n\nTo view some important output parameters of the provisioned database create the `output.tf` file with these output variables:\n\n```hcl path=output.tf\noutput \"db_connection_composed\" {\n  value = ibm_database.db_instance.connectionstrings.0.composed\n}\noutput \"db_connection_certbase64\" {\n  value = ibm_database.db_instance.connectionstrings.0.certbase64\n}\n```\n\nIf you need more parameters, add the following output variables to get all the parameters, then add variables with the values of the parameters of the `connectionstrings` or `db_instance` JSON objects.\n\n```hcl\noutput \"db_connection_string\" {\n  value = ibm_database.db_instance.connectionstrings.0\n}\noutput \"instance\" {\n  value = ibm_database.db_instance\n}\n```\n\nTo define the value of the admin password variable export the variable `TF_VAR_db_admin_password` with a password with 10-32 characters or use the following command to generate a random password. The password will be used by the URI in the variable `PASSWORD`, so we are exporting both.\n\n```bash\nexport PASSWORD=$(LC_CTYPE=C tr -dc 'a-zA-Z0-9' < /dev/urandom | head -c 32)\nexport TF_VAR_db_admin_password=$PASSWORD\n```\n\nTo create the database just execute the following terraform commands:\n\n```bash\nterraform init\nterraform plan\nterraform apply\n```\n\nYou'll see the output of the last command with the connection string URI with the variable `db_connection_composed` and the CA certificate encoded with base64 in the variable `db_connection_certbase64`. To get the output varibles again use the command `terraform output`.\n\nYou'll need to save the output variables into environment variables and the certificate to a file executing these commands. In order to interpolate the `PASSWORD` variable into the `APP_POSTGRESQL_URI` variable you have to use the `eval` command like so.\n\n```bash\nterraform output db_connection_certbase64 | base64 --decode > db_ca.crt\nexport PASSWORD=$(terraform output db_admin_password)\nexport APP_POSTGRESQL_URI=$(eval 'echo \"'$(terraform output db_connection_composed)'\"')\n```\n\nThe database name in the URI is `ibmclouddb`, assumig the DB name is `demo` let's use the `sed` command to change it, like so:\n\n```bash\nexport DB_NAME=demo\nexport APP_POSTGRESQL_URI=$(echo $APP_POSTGRESQL_URI | sed \"s|/ibmclouddb?|/$DB_NAME?|\")\necho $APP_POSTGRESQL_URI\n```\n\nAll you need to conect to the database is the conection URI, from the environment variable `APP_POSTGRESQL_URI`, and the CA Certificate, stored in the file `./db_ca.crt`.\n\n## Access to the PostgreSQL database with NodeJS\n\nFor simplicity let's create this code in NodeJS to use the conection string and connect to the database. A similar code can be made in any other programming language.\n\nLet's install the PostgreSQL client [pgAdmin](https://www.pgadmin.org/download/) which is GUI/Web client. It can also be installed on Mac OS X with `brew`.\n\n```bash\nbrew cask install pgadmin4\n```\n\nTo connect to the Cloud Database using pgAdmin read the [documentation](https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-getting-started) or follow this quick instructions:\n\n1. Add a New Server with any given name (i.e. `ibmcloud`)\n2. Go to the Connection tab, enter the **Host name** and **Port** from the `APP_POSTGRESQL_URI` variable.\n3. Enter the **Password** from the `PASSWORD` variable.\n4. Go to the SSL tab, click on the 3 dots to select the `db_ca.crt` file under the **Root certificate** field.\n5. Click on the **Save** button.\n\nUsing the GUI or the Query Tool (**Tools** > **Query Tool**), create the database `demo`.\n\n```sql\nCREATE DATABASE demo;\n```\n\nSelect the new database with the right click to open the **Query Tool** on the new database. Create the table `users` and insert a few records using the following SQL instruction:\n\n```sql\nCREATE TABLE users (\n  ID SERIAL PRIMARY KEY,\n  name VARCHAR(30),\n  email VARCHAR(30),\n  age INT\n);\n\nINSERT INTO users (name, email, age)\n  VALUES\n    ('Dale Duffy', 'daleduffy@dognosis.com', 21),\n    ('Price West', 'pricewest@dognosis.com', 36);\n```\n\nVerify the data either using the GUI or executing the following SQL instructions\n\n```sql\nSELECT * FROM users;\n```\n\nCreate a new NodeJS application and install the `pg` packages.\n\n```bash\nmkdir app\ncd app\nnpm init\nnpm install pg\n```\n\nCreate the `index.js` with the following code to connect to the database, get the list of users and insert a new one.\n\n```javascript\nconst { Pool, Client } = require(\"pg\");\nconst { readFileSync } = require(\"fs\");\nconst { join } = require(\"path\");\n\nconst connectionString = process.env.APP_POSTGRESQL_URI;\nconst caCertPath = join(__dirname, \"..\", \"db_ca.crt\");\nconst caCert = readFileSync(caCertPath);\n\n(async () => {\n  const pool = new Pool({\n    connectionString: connectionString,\n    ssl: {\n      ca: caCert,\n      rejectUnauthorized: true,\n    },\n  });\n\n  const resBefore = await pool.query(\"SELECT * FROM users\");\n  console.info(resBefore.rows);\n\n  pool.query(\"INSERT INTO users (name, email, age) VALUES ($1, $2, $3)\", [\n    \"Arline Gordon\",\n    \"arlinegordon@dognosis.com\",\n    29,\n  ]);\n\n  const resAfter = await pool.query(\"SELECT * FROM users\");\n  console.info(resAfter.rows);\n\n  await pool.end();\n})();\n```\n\nExecute yuour code with the command:\n\n```bash\nnode .\n```\n\nRefer to the [documentation](https://cloud.ibm.com/docs/databases-for-postgresql) to know more about PostgreSQL database on IBM Cloud.\n\n## Service Instances\n\nThe `ibm_resource_instance` resource can be used to create, update or delete any of the offered services by IBM Cloud. You can retrieve list of offered services by installing the `catalogs-management` CLI plug-in and running the `service-marketplace` or `search` subcommands of such plugin.\n\n```bash\nibmcloud plugin install catalogs-management\n\nibmcloud catalog search\n\nibmcloud catalog service-marketplace\nibmcloud catalog service-marketplace | grep message\n\nibmcloud catalog service mqcloud\n```\n\nYou can use the same plugin to create the service however, in this page we'll cover how to manage the service with Terraform, using the resource `ibm_resource_instance`.\n\nThe following table list the most relevant input parameters for the `ibm_resource_instance` resource.\n\n| Input parameter | Description |\n|---|---|\n| `name` | name to identify the resource instance |\n| `service` | name of the service offering |\n| `plan` | name of the plan type supported by service. You can retrieve the value by running the `ibmcloud catalog service <servicename>` command |\n| `location` | target location or environment to create the resource instance |\n| `resource_group_id` | ID of the resource group where you want to create the service. You can retrieve the value from data source `ibm_resource_group`. By default uses the Default resource group |\n| `parameters` | Arbitrary parameters to create instance. The value must be a JSON object |\n\n## Message Queue\n\nIn this section we'll see an example to create a Message & Queue service using the `ibm_resource_instance` resource. Create the file `mq.tf` with the `ibm_resource_instance` resource to create an `mqcloud` service.\n\n```hcl path=mq.rf\nresource \"ibm_resource_instance\" \"resource_instance\" {\n  name              = \"mq-instance-test\"\n  service           = \"mqcloud\"\n  plan              = \"default\"\n  location          = \"us-south\"\n  resource_group_id = data.ibm_resource_group.group.id\n  tags              = [\"message queue\", \"testmq\"]\n\n  timeouts {\n    create = \"15m\"\n    update = \"15m\"\n    delete = \"15m\"\n  }\n}\n```\n\nA simple `main.tf` file to use the above code would be like this:\n\n```hcl path=main.tf\nprovider \"ibm\" {\n  region     = \"us-south\"\n  generation = 2\n}\n\ndata \"ibm_resource_group\" \"group\" {\n  name = \"Default\"\n}\n```\n\nExecute this code with the following terraform commands:\n\n```bash\nterraform init\nterraform plan\nterraform apply\n```\n\nRefer to the [documentation](https://cloud.ibm.com/docs/mqcloud) to know how to use the MQ service from CLI, the Web Console or your own application.\n\n## Final Terraform code\n\nThe only cloud database service used in the complete demo application is MongoDB. You can download the code from the GitHub repository https://github.com/IBM/cloud-enterprise-examples/ in the directory [08_cloud-services](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services). This code builds off the compute example by adding the following resources and code.\n\nThe database definition file `db.tf` using the `ibm_database` resource.\n\n```hcl path=db.tf\nresource \"ibm_database\" \"iac_app_db_instance\" {\n  name              = var.db_name\n  plan              = var.db_plan\n  location          = var.region\n  service           = \"databases-for-mongodb\"\n  resource_group_id = data.ibm_resource_group.group.id\n\n  adminpassword                = var.db_admin_password\n  members_memory_allocation_mb = var.db_memory_allocation\n  members_disk_allocation_mb   = var.db_disk_allocation\n}\n```\n\nAppending the new defined variables in the `variables.tf` file.\n\n```hcl path=variables.tf\nvariable \"db_plan\" {\n  default = \"standard\"\n}\nvariable \"db_name\" {\n  default = \"moviedb\"\n}\nvariable \"db_admin_password\" {\n  default = \"inSecureP@55w0rd\"\n}\nvariable \"db_memory_allocation\" {\n  default = \"3072\"\n}\nvariable \"db_disk_allocation\" {\n  default = \"61440\"\n}\n```\n\nThe `compute.tf` file has a new Cloud-Init code in the VSI, like so:\n\n```hcl path=compute.tf\nresource \"ibm_is_instance\" \"iac_app_instance\" {\n  ...\n\n  user_data = <<-EOUD\n            #!/bin/bash\n            mkdir -p /app\n\n            # Application script and dependencies\n            echo '${data.local_file.requirements.content_base64}' | base64 --decode > /app/requirements.txt\n            echo '${data.local_file.app.content_base64}' | base64 --decode > /app/app.py\n            # Script and database to initially import\n            echo '${data.local_file.db.content_base64}' | base64 --decode > /app/db.json\n            echo '${data.local_file.import.content_base64}' | base64 --decode > /app/import.py\n            # Configuration and credentials\n            echo '${ibm_database.iac_app_db_instance.connectionstrings.0.certbase64}' | base64 --decode > /app/db_certificate.cert\n            export PASSWORD=${var.db_admin_password}\n            export APP_MONGODB_URI=\"${ibm_database.iac_app_db_instance.connectionstrings.0.composed}\"\n            export APP_PORT=${var.port}\n\n\n            # https://askubuntu.com/questions/1154892/prevent-question-restart-services-during-package-upgrades-without-asking\n            echo '* libraries/restart-without-asking boolean true' | debconf-set-selections\n\n            # Python3 is installed by default, pip3 is not\n            apt update\n            apt install -y python3-pip\n\n            # Setup and initialize the DB\n            cd /app\n            pip3 install -r requirements.txt\n            python3 import.py\n\n            # Start up the application\n            python3 app.py &\n            EOUD\n\n  ...\n}\n```\n\nIn order to have access to the applications and dependencies file listed below we need to the fine the following terraform data sources with the files content.\n\n```hcl path=app.tf\ndata \"local_file\" \"app\" {\n  filename = \"${path.module}/app/app.py\"\n}\n\ndata \"local_file\" \"import\" {\n  filename = \"${path.module}/app/import.py\"\n}\n\ndata \"local_file\" \"requirements\" {\n  filename = \"${path.module}/app/requirements.txt\"\n}\n\ndata \"local_file\" \"db\" {\n  filename = \"${path.module}/app/db.min.json\"\n}\n```\n\nAnd these files are in the `app/` folder. The `app/app.py` file is the API application using `flask`, `flask-restful` and `flask_mongoengine` packages.\n\n```python path=app/app.py\nfrom flask import Flask, Response, request\nfrom flask_restful import Api, Resource\nfrom flask_mongoengine import MongoEngine\nfrom datetime import datetime\nimport json\nimport os\nimport logging\nimport ssl\n\nlogging.basicConfig(filename='app.log',\n                    level=logging.DEBUG)\nmongodb_uri = os.environ.get('APP_MONGODB_URI')\nif not mongodb_uri:\n    mongodb_uri = 'mongodb://localhost/moviedb'\nport = os.environ.get('APP_PORT')\nif not port:\n    port = '8080'\napp = Flask(__name__)\napp.config['MONGODB_SETTINGS'] = {\n    'MONGODB_HOST': mongodb_uri,\n    'MONGODB_DB': 'moviedb',\n    'MONGODB_SSL': True,\n    'MONGODB_SSL_CERT_REQS': ssl.CERT_REQUIRED,\n    'MONGODB_SSL_CA_CERTS': '/app/db_certificate.cert'\n}\napi = Api(app)\ndb = MongoEngine()\ndb.init_app(app)\n\nclass Movie(db.Document):\n    title = db.StringField(required=True)\n    titleSort = db.StringField()\n    originalTitle = db.StringField()\n    contentRating = db.StringField()\n    rating = db.FloatField()\n    ratingImage = db.StringField()\n    audienceRating = db.FloatField()\n    audienceRatingImage = db.StringField()\n    hasPremiumPrimaryExtra = db.IntField()\n    summary = db.StringField(required=False)\n    year = db.IntField(required=False)\n    tagline = db.StringField()\n    duration = db.IntField(required=False)\n    originallyAvailableAt = db.StringField(required=False)\n    addedAt = db.IntField(\n        default=datetime.timestamp(datetime.now()), required=False)\n    updatedAt = db.IntField(\n        default=datetime.timestamp(datetime.now()), required=False)\n    genre = db.StringField(required=True)\n    # genre = db.ListField(required=True)\n    director = db.ListField(db.StringField(), required=True)\n    writer = db.ListField(db.StringField(), required=False)\n    country = db.StringField(required=False)\n    cast = db.ListField(db.StringField(), required=True)\n\nclass MoviesApi(Resource):\n    def get(self):\n        movies = Movie.objects().to_json()\n        return Response(movies, mimetype=\"application/json\", status=200)\n\n    def post(self):\n        body = request.get_json()\n        movie = Movie(**body).save()\n        id = movie.id\n        return {'id': str(id)}, 200\n\nclass MovieApi(Resource):\n    def put(self, id):\n        body = request.get_json()\n        Movie.objects.get(id=id).update(**body)\n        return '', 200\n\n    def delete(self, id):\n        Movie.objects.get(id=id).delete()\n        return '', 200\n\n    def get(self, id):\n        movie = Movie.objects.get(id=id).to_json()\n        return Response(movie, mimetype=\"application/json\", status=200)\n\napi.add_resource(MoviesApi, '/api/movies')\napi.add_resource(MovieApi, '/api/movies/<id>')\n\n@app.route('/api/healthcheck')\ndef health_check():\n    return {'HealthCheckResponse': True}\n\napp.run(host='0.0.0.0', port=port)\n```\n\nThe `import.py` application is executed before the API application on every instance created, however it only import the JSON db the first time it's executed, so this avoid repeated documents or records. Similar to the simple Python application showed in this page, it uses the `pymongo` package to connect to the DB and insert all the documents.\n\n```python path=app/import.py\nfrom pymongo import MongoClient\nimport json\nimport os\n\nmongodb_uri = os.environ.get('APP_MONGODB_URI')\nif not mongodb_uri:\n    mongodb_uri = 'mongodb://localhost/moviedb'\n\nclient = MongoClient(mongodb_uri,\n                     ssl=True,\n                     ssl_ca_certs=\"/app/db_certificate.cert\")\n\ndbnames = client.list_database_names()\n\nif not 'moviedb' in dbnames:\n    db = client['moviedb']\n    movies = db['movie']\n    with open('./db.json') as f:\n        data = json.load(f)\n    movies.insert_many(data['movies'])\n\nclient.close()\n```\n\nLast but not least, the `requirements.txt` file with the Python packages required for this demo.\n\n```python path=app/requirements.txt\nflask\nflask-restful\nflask-mongoengine\npymongo\n```\n\n## Clean up\n\nFinally, when you finish using the infrastructure for any of the presented examples, cleanup everything you created with the execution of:\n\n```bash\nterraform destroy\n```\n\nIf the example was created with IBM Cloud Schematics, cleanup everything you created with the execution of:\n\n```bash\n\nibmcloud schematics destroy --id $WORKSPACE_ID # Identify the Activity_ID\nibmcloud schematics logs  --id $WORKSPACE_ID --act-id Activity_ID\n\n# ... wait until it's done\n\nibmcloud schematics workspace delete --id $WORKSPACE_ID\nibmcloud schematics workspace list\n```\n","type":"Mdx","contentDigest":"a7ae6f0fc2a9e795a8c9c7555cd0886d","counter":819,"owner":"gatsby-plugin-mdx"},"frontmatter":{"title":"IaC for Cloud Databases and Service Instances","description":"Use IaC to work with managed Cloud Databases and Service Instances","keywords":"terraform,ibm cloud,db,dba"},"exports":{},"rawBody":"---\ntitle: IaC for Cloud Databases and Service Instances\ndescription: Use IaC to work with managed Cloud Databases and Service Instances\nkeywords: 'terraform,ibm cloud,db,dba'\n---\n\n<!--\n\nThe pattern to document the resources is like follow:\n- Introduce the resource with an example\n- List all or the most important input parameters\n- If will be used, list the most important output parameters\n- Provide instructions to get the value of the input parameters, either using `ibmcloud`, API or the Web console.\n- If needed, instructions to execute the code either with Terraform or Schematics\n\n-->\n\n<PageDescription>\n\nUse IaC to work with managed Cloud Databases and Service Instances\n\n</PageDescription>\n\nMost of the applications requires a database or service. This page explains how to use the `ibm_database` and `ibm_resource_instance` resources to create different type of databases or services. We will use the API movies demo application to demonstrate the use of a provisioned MongoDB database. The following diagram shows the architecture we will build in this page.\n\n![Architecture](./images/IaC-Cloud_Services_Resources.png \"Cloud Database Resources Architecture\")\n\nThe code to build these resources can be downloaded from the GitHub repository https://github.com/IBM/cloud-enterprise-examples/ in the directory [08_cloud-services](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services).\n\n<AnchorLinks small>\n  <AnchorLink>Cloud Database Services</AnchorLink>\n  <AnchorLink>MongoDB</AnchorLink>\n  <AnchorLink>Access the database with MongoDB Compass</AnchorLink>\n  <AnchorLink>Access to the MongoDB database with Python</AnchorLink>\n  <AnchorLink>PostgreSQL</AnchorLink>\n  <AnchorLink>Access to the PostgreSQL database with NodeJS</AnchorLink>\n  <AnchorLink>Service Instances</AnchorLink>\n  <AnchorLink>Message Queue</AnchorLink>\n  <AnchorLink>Final Terraform code</AnchorLink>\n  <AnchorLink>Clean up</AnchorLink>\n</AnchorLinks>\n\nAs you look at the PostgreSQL & MongoDB code, you will notice the similarity.  In fact, except for the `service` type, they are identical.  This is because the scripts are using Resource Management Resources and managing resources for the IBM Cloud database services.  You can find out more about it [here](https://cloud.ibm.com/docs/terraform?topic=terraform-resource-mgmt-resources#resource-instance).\n\n## Cloud Database Services\n\n[IBM Cloud Database](https://www.ibm.com/cloud/databases) offers many database options, with each one being useful for a particular use-case. The IBM Cloud Provider supports creation of [Cloud Databases resources](https://cloud.ibm.com/docs/terraform?topic=terraform-databases-resources) of several different flavors including: **etcd**, **PostgreSQL**, **Redis**, **ElasticSearch**, **MongoDB** and messaging with **RabbitMQ**.\n\nTo create a Cloud Database we use the Terraform resource `ibm_database`. No matter what database flavor is provisioned, we always provide the same input parameters and get the same output parameters. The DB flavor will only affect the values of these parameters.\n\nThe following table lists the most relevant input parameters for the `ibm_database` resource.\n\n| Input parameter | Description |\n|---|---|\n| `name` | name to identify the _database instance_.  The name must not include spaces. Notice that this is not the name as the database |\n| `plan` | service plan that you choose for your instance. The supported values is `standard` |\n| `location` | location to deploy your instance, it must match the region parameter that you specify in the provider block |\n| `tags` | optional list of tags to add to your instance |\n| `service` | type of Cloud Databases to create, the following services are accepted: `databases-for-etcd`, `databases-for-postgresql`, `databases-for-mongodb`, `databases-for-redis`, `databases-for-elasticsearch` and `messages-for-rabbitmq` |\n| `adminpassword`\t| password for the database administrator. If not specified, additional users must be specified in a user block |\n| `members_memory_allocation_mb` | amount of memory in megabytes for the database, split across all members |\n| `members_disk_allocation_mb` | amount of disk space for the database, split across all members |\n| `members_cpu_allocation_count` | allocates the number of specified dedicated cores to your deployment |\n| `backup_id` | CRN of a backup resource to restore from. The backup must have been created by a database deployment with the same service ID. The backup is loaded after provisioning and the new deployment starts up that uses that data. A backup CRN is in the format `crn:v1:<…>:backup:`. If omitted, the database is provisioned empty |\n| `key_protect_key` | CRN of a Key Protect root key that you want to use for disk encryption. A key protect CRN is in the format `crn:v1:<…>:key:` |\n| `key_protect_instance` | CRN of a Key Protect instance that you want to use for disk encryption. A key protect CRN is in the format `crn:v1:<…>::` |\n| `service_endpoints` | to enable the `public`, `private`, or both `public-and-private` service endpoints. The default is `public` |\n| `users` | list of users to create on the database. Multiple blocks are allowed |\n| `users.name` | name of the user ID to add to the database instance. The user ID must be between 5 and 32 characters |\n| `users.password` | password for the user ID. The password must be between 10 and 32 characters |\n| `whitelist` | list of IP addresses to allow access for the database. Multiple blocks are allowed. If not specified access from any IP is allowed |\n| `whitelist.address` | The IP address or range of database client addresses to be whitelisted in CIDR format. Example: `172.168.1.2/32` |\n\nThe list of output parameters is like follows:\n\n| Input parameter | Description |\n|---|---|\n| `id` | CRN of the database instance |\n| `status` | status of the instance |\n| `adminuser` | user ID of the database administrator. Example: `admin` or `root` |\n| `version` | database version |\n| `connectionstrings` | list of [connection strings](https://cloud.ibm.com/docs/services/databases-for-postgresql?topic=databases-for-postgresql-connection-strings) for the database for each user ID. The results are returned in pairs of the userid and string: `connectionstrings.1.name = admin connectionstrings.1.string = postgres://admin:$PASSWORD@79226bd4-4076-4873-b5ce-b1dba48ff8c4.b8a5e798d2d04f2e860e54e5d042c915.databases.appdomain.cloud:32554/ibmclouddb?sslmode=verify-full` Individual string parameters can be retrieved using Terraform variables and outputs `connectionstrings.x.hosts.x.port` and `connectionstrings.x.hosts.x.host` |\n\nThe following sections will explain how to create a simple Cloud Database with **MongoDB** and **PostgreSQL**. To view an example of **etcd**, refer to the section [Setup Terraform Remote State using etcd as backend](/iac/getting-started-terraform/remote-state).\n\n## MongoDB\n\nThis is a simple example to create a single instance running MongoDB. The final code can be found in the directory [08_cloud-services/simple_mongodb](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services/simple_mongodb) of the GitHub repository with all the code patterns. A full example with application setup on VSI compute can be found in the [08_cloud-services](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services) and is discussed towards the end of this article.\n\nTo create a MongoDB Cloud Database use the service `databases-for-mongodb`. Create a file to store the database definition (i.e. `db.tf`) with a code similar to this one:\n\n```hcl path=db.tf\nvariable \"db_admin_password\" {}\n\nresource \"ibm_database\" \"db_instance\" {\n  name              = \"sampledb\"\n  plan              = \"standard\"\n  location          = \"us-south\"\n  service           = \"databases-for-mongodb\"\n  resource_group_id = data.ibm_resource_group.group.id\n\n  adminpassword                = var.db_admin_password\n  members_memory_allocation_mb = \"3072\"\n  members_disk_allocation_mb   = \"61440\"\n}\n```\n\nA simple `main.tf` code to use the previous database would be like so:\n\n```hcl path=main.tf\nprovider \"ibm\" {\n  region     = \"us-south\"\n  generation = 2\n}\n\ndata \"ibm_resource_group\" \"group\" {\n  name = \"Default\"\n}\n```\n\nTo view some important output parameters of the provisioned database create the `output.tf` file with these output variables:\n\n```hcl path=output.tf\noutput \"db_connection_composed\" {\n  value = ibm_database.db_instance.connectionstrings.0.composed\n}\noutput \"db_connection_certbase64\" {\n  value = ibm_database.db_instance.connectionstrings.0.certbase64\n}\noutput \"db_admin_password\" {\n  value = var.db_admin_password\n}\n```\n\nIf you need more parameters, add the following output variables to get all the parameters, then add variables with the values of the parameters of the `connectionstrings` or `db_instance` JSON objects.\n\n```hcl\noutput \"db_connection_string\" {\n  value = ibm_database.db_instance.connectionstrings.0\n}\noutput \"instance\" {\n  value = ibm_database.db_instance\n}\n```\n\nTo define the value of the admin password variable export the variable `TF_VAR_db_admin_password` with a password with 10-32 characters or use the following command to generate a random password. The password will be used by the URI in the variable `PASSWORD`, so we are exporting both.\n\n```bash\nexport PASSWORD=$(LC_CTYPE=C tr -dc 'a-zA-Z0-9' < /dev/urandom | head -c 32)\nexport TF_VAR_db_admin_password=$PASSWORD\n```\n\nTo create the database just execute the following terraform commands:\n\n```bash\nterraform init\nterraform plan\nterraform apply\n```\n\nYou'll see the output of the last command with the connection string URI with the variable `db_connection_composed` and the CA certificate encoded with base64 in the variable `db_connection_certbase64`. To get the output varibles again use the command `terraform output`.\n\nYou'll need to save the output variables into environment variables and the certificate to a file executing these commands. In order to interpolate the `PASSWORD` variable into the `APP_MONGODB_URI` variable you have to use the `eval` command like so.\n\n```bash\nterraform output db_connection_certbase64 | base64 --decode > db_ca.crt\nexport PASSWORD=$(terraform output db_admin_password)\nexport APP_MONGODB_URI=$(eval 'echo \"'$(terraform output db_connection_composed)'\"')\necho $APP_MONGODB_URI\n```\n\n<!--\nThe database name in the URI is `ibmclouddb`, assumig the DB name is `demodb` let's use the `sed` command to change it, like so:\n\n```bash\nexport DB_NAME=demodb\nexport APP_MONGODB_URI=$(echo $APP_MONGODB_URI | sed 's|/ibmclouddb?|/$DB_NAME?|')\necho $APP_MONGODB_URI\n```\n-->\n\nAll you need to conect to the database is the conection URI, from the environment variable `APP_MONGODB_URI`, and the CA Certificate, stored in the file `./db_ca.crt`.\n\n## Access the database with MongoDB Compass\n\nLet's use the client MongoDB Compass to access the new provisioned database. Download and install the [MongoDB Compass](https://www.mongodb.com/try/download/compass) application for your platform. Alternatively you can use the `brew` command on Mac OS X to install it.\n\n```bash\nbrew cask install mongodb-compass\n```\n\nOpen MongoDB Compass and you'll see the new connection screen. Copy and paste the connection URI from the environment variable `APP_MONGODB_URI` in the **Paste your connection string** field.\n\n![](./images/mongodb_compass_1.png)\n\nClick on **Fill in connection fields individually**, then select the **More Options** tab. Select **Server Validation** in the **SSL** field, then select the `db_ca.crt` file in the **Certificate Authority** field.\n\n![](./images/mongodb_compass_2.png)\n\nCreate a database clicking on the **CREATE DATABASE** button. Name the database `demodb` and the collection `users`.\n\n![](./images/mongodb_compass_3.png)\n\nClick on the **demodb** database, click on the **users** collection, then on ADD DATA > Insert Document to add any data you want, like the following example:\n\n![](./images/mongodb_compass_4.png)\n\n```json\n[\n  {\n    \"_id\": \"5ee428b13265d9083baa0259\",\n    \"index\": 0,\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 21,\n    \"name\": \"Dale Duffy\",\n    \"gender\": \"male\",\n    \"email\": \"daleduffy@dognosis.com\"\n  },\n  {\n    \"_id\": \"5ee428b19eeb7916a4943a64\",\n    \"index\": 1,\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 36,\n    \"name\": \"Price West\",\n    \"gender\": \"male\",\n    \"email\": \"pricewest@dognosis.com\"\n  },\n  {\n    \"_id\": \"5ee428b198517601184ee994\",\n    \"index\": 2,\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 29,\n    \"name\": \"Arline Gordon\",\n    \"gender\": \"female\",\n    \"email\": \"arlinegordon@dognosis.com\"\n  },\n  {\n    \"_id\": \"5ee428b1cd9893fad62cf901\",\n    \"index\": 3,\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 37,\n    \"name\": \"Mathis Gould\",\n    \"gender\": \"male\",\n    \"email\": \"mathisgould@dognosis.com\"\n  },\n  {\n    \"_id\": \"5ee428b19e46e16ef1284030\",\n    \"index\": 4,\n    \"picture\": \"http://placehold.it/32x32\",\n    \"age\": 30,\n    \"name\": \"Rosemarie Morton\",\n    \"gender\": \"female\",\n    \"email\": \"rosemariemorton@dognosis.com\"\n  }\n]\n```\n\nThere is more information about how to use MongoDB Compass [with the IBM Cloud Database](https://cloud.ibm.com/docs/databases-for-mongodb?topic=databases-for-mongodb-getting-started) or about how to use [MongoDB Compass](https://docs.mongodb.com/compass/current/) in general.\n\n## Access to the MongoDB database with Python\n\nFor simplicity let's create this code in Python to use the conection string and connect to the database. A similar code can be made in any other programming language.\n\nIn this example we'll use the [pymongo](https://pypi.org/project/pymongo/) package and a JSON file with mock data to import into the database. All the code is located in the directory [08_cloud-services/simple_mongodb](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services/simple_mongodb) of the GitHub repository with all the code patterns.\n\nThe `pymongo` package requires the connection URI, obtained from the environment variable `APP_MONGODB_URI` and the CA certificate from the file `db_ca.crt`, like so.\n\n```python\nfrom pymongo import MongoClient\nimport os\n\nmongodb_uri = os.environ.get('APP_MONGODB_URI')\n\nclient = MongoClient(mongodb_uri,\n                     ssl=True,\n                     ssl_ca_certs=\"./db_ca.crt\")\n```\n\nThe rest of the application is a sample code to insert many documents or just one, to find documents and query the database. Similar sample code can be found in the pymongo [documentation](https://pypi.org/project/pymongo/) or in this [tutorial](https://www.w3schools.com/python/python_mongodb_getstarted.asp). The entire code is shown below and also can be downloaded from [here](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services/simple_mongodb/app.py).\n\n```python path=app.py\nfrom pymongo import MongoClient\nimport json\nimport os\n\nmongodb_uri = os.environ.get('APP_MONGODB_URI')\n\nclient = MongoClient(mongodb_uri,\n                     ssl=True,\n                     ssl_ca_certs=\"./db_ca.crt\")\n\ndbnames = client.list_database_names()\n\ndb = client['demodb']\nbooks = db['books']\n\nif not books.find_one():\n    with open('./db.json') as f:\n        data = json.load(f)\n    books.insert_many(data['books'])\n\nnew_book = {\n    \"isbn\": \"9781449325862\",\n    \"title\": \"Git Pocket Guide\",\n    \"subtitle\": \"A Working Introduction\",\n    \"author\": \"Richard E. Silverman\",\n    \"published\": \"2013-08-02T00:00:00.000Z\",\n    \"publisher\": \"O'Reilly Media\",\n    \"pages\": 234,\n    \"description\": \"This pocket guide is the perfect on-the-job companion to Git, the distributed version control system. It provides a compact, readable introduction to Git for new users, as well as a reference to common commands and procedures for those of you with Git experience.\",\n    \"website\": \"http://chimera.labs.oreilly.com/books/1230000000561/index.html\"\n}\n\nif books.count_documents({\"isbn\": new_book['isbn']}) == 0:\n    book = books.insert_one(new_book)\n    print(\"The new book has been inserted. ID = \", book.inserted_id)\n\nprint(\"Books:\")\nfor book in books.find({}, {\"title\": 1}):\n    print(\"\\t\", book)\n\nquery = {\"publisher\": \"O'Reilly Media\"}\nprint(\"O'Reilly Media's Books:\")\nfor book in books.find(query, {\"title\": 1, \"publisher\": 1}):\n    print(\"\\t\", book)\n\nclient.close()\n```\n\n## PostgreSQL\n\nThis is another simple example to create a single instance running PostgreSQL. The final code can be found in the directory [08_cloud-services/simple_postgresql](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services/simple_postgresql) of the GitHub repository with all the code patterns.\n\nTo create a PostgreSQL Cloud Database use the service `databases-for-postgresql`. Create a file to store the database definition (i.e. `db.tf`) with a code similar to this one:\n\n```hcl path=db.tf\nresource \"ibm_database\" \"db_instance\" {\n  name              = \"sampledb\"\n  plan              = \"standard\"\n  location          = \"us-south\"\n  service           = \"databases-for-postgresql\"\n  resource_group_id = data.ibm_resource_group.group.id\n\n  adminpassword                = \"P@ssW0rd\"\n  members_memory_allocation_mb = \"3072\"\n  members_disk_allocation_mb   = \"61440\"\n}\n```\n\nA simple `main.tf` code to use the previous database would be like so:\n\n```hcl path=main.tf\nprovider \"ibm\" {\n  region             = \"us-south\"\n  generation         = 2\n}\n\ndata \"ibm_resource_group\" \"group\" {\n  name = \"Default\"\n}\n```\n\nTo view some important output parameters of the provisioned database create the `output.tf` file with these output variables:\n\n```hcl path=output.tf\noutput \"db_connection_composed\" {\n  value = ibm_database.db_instance.connectionstrings.0.composed\n}\noutput \"db_connection_certbase64\" {\n  value = ibm_database.db_instance.connectionstrings.0.certbase64\n}\n```\n\nIf you need more parameters, add the following output variables to get all the parameters, then add variables with the values of the parameters of the `connectionstrings` or `db_instance` JSON objects.\n\n```hcl\noutput \"db_connection_string\" {\n  value = ibm_database.db_instance.connectionstrings.0\n}\noutput \"instance\" {\n  value = ibm_database.db_instance\n}\n```\n\nTo define the value of the admin password variable export the variable `TF_VAR_db_admin_password` with a password with 10-32 characters or use the following command to generate a random password. The password will be used by the URI in the variable `PASSWORD`, so we are exporting both.\n\n```bash\nexport PASSWORD=$(LC_CTYPE=C tr -dc 'a-zA-Z0-9' < /dev/urandom | head -c 32)\nexport TF_VAR_db_admin_password=$PASSWORD\n```\n\nTo create the database just execute the following terraform commands:\n\n```bash\nterraform init\nterraform plan\nterraform apply\n```\n\nYou'll see the output of the last command with the connection string URI with the variable `db_connection_composed` and the CA certificate encoded with base64 in the variable `db_connection_certbase64`. To get the output varibles again use the command `terraform output`.\n\nYou'll need to save the output variables into environment variables and the certificate to a file executing these commands. In order to interpolate the `PASSWORD` variable into the `APP_POSTGRESQL_URI` variable you have to use the `eval` command like so.\n\n```bash\nterraform output db_connection_certbase64 | base64 --decode > db_ca.crt\nexport PASSWORD=$(terraform output db_admin_password)\nexport APP_POSTGRESQL_URI=$(eval 'echo \"'$(terraform output db_connection_composed)'\"')\n```\n\nThe database name in the URI is `ibmclouddb`, assumig the DB name is `demo` let's use the `sed` command to change it, like so:\n\n```bash\nexport DB_NAME=demo\nexport APP_POSTGRESQL_URI=$(echo $APP_POSTGRESQL_URI | sed \"s|/ibmclouddb?|/$DB_NAME?|\")\necho $APP_POSTGRESQL_URI\n```\n\nAll you need to conect to the database is the conection URI, from the environment variable `APP_POSTGRESQL_URI`, and the CA Certificate, stored in the file `./db_ca.crt`.\n\n## Access to the PostgreSQL database with NodeJS\n\nFor simplicity let's create this code in NodeJS to use the conection string and connect to the database. A similar code can be made in any other programming language.\n\nLet's install the PostgreSQL client [pgAdmin](https://www.pgadmin.org/download/) which is GUI/Web client. It can also be installed on Mac OS X with `brew`.\n\n```bash\nbrew cask install pgadmin4\n```\n\nTo connect to the Cloud Database using pgAdmin read the [documentation](https://cloud.ibm.com/docs/databases-for-postgresql?topic=databases-for-postgresql-getting-started) or follow this quick instructions:\n\n1. Add a New Server with any given name (i.e. `ibmcloud`)\n2. Go to the Connection tab, enter the **Host name** and **Port** from the `APP_POSTGRESQL_URI` variable.\n3. Enter the **Password** from the `PASSWORD` variable.\n4. Go to the SSL tab, click on the 3 dots to select the `db_ca.crt` file under the **Root certificate** field.\n5. Click on the **Save** button.\n\nUsing the GUI or the Query Tool (**Tools** > **Query Tool**), create the database `demo`.\n\n```sql\nCREATE DATABASE demo;\n```\n\nSelect the new database with the right click to open the **Query Tool** on the new database. Create the table `users` and insert a few records using the following SQL instruction:\n\n```sql\nCREATE TABLE users (\n  ID SERIAL PRIMARY KEY,\n  name VARCHAR(30),\n  email VARCHAR(30),\n  age INT\n);\n\nINSERT INTO users (name, email, age)\n  VALUES\n    ('Dale Duffy', 'daleduffy@dognosis.com', 21),\n    ('Price West', 'pricewest@dognosis.com', 36);\n```\n\nVerify the data either using the GUI or executing the following SQL instructions\n\n```sql\nSELECT * FROM users;\n```\n\nCreate a new NodeJS application and install the `pg` packages.\n\n```bash\nmkdir app\ncd app\nnpm init\nnpm install pg\n```\n\nCreate the `index.js` with the following code to connect to the database, get the list of users and insert a new one.\n\n```javascript\nconst { Pool, Client } = require(\"pg\");\nconst { readFileSync } = require(\"fs\");\nconst { join } = require(\"path\");\n\nconst connectionString = process.env.APP_POSTGRESQL_URI;\nconst caCertPath = join(__dirname, \"..\", \"db_ca.crt\");\nconst caCert = readFileSync(caCertPath);\n\n(async () => {\n  const pool = new Pool({\n    connectionString: connectionString,\n    ssl: {\n      ca: caCert,\n      rejectUnauthorized: true,\n    },\n  });\n\n  const resBefore = await pool.query(\"SELECT * FROM users\");\n  console.info(resBefore.rows);\n\n  pool.query(\"INSERT INTO users (name, email, age) VALUES ($1, $2, $3)\", [\n    \"Arline Gordon\",\n    \"arlinegordon@dognosis.com\",\n    29,\n  ]);\n\n  const resAfter = await pool.query(\"SELECT * FROM users\");\n  console.info(resAfter.rows);\n\n  await pool.end();\n})();\n```\n\nExecute yuour code with the command:\n\n```bash\nnode .\n```\n\nRefer to the [documentation](https://cloud.ibm.com/docs/databases-for-postgresql) to know more about PostgreSQL database on IBM Cloud.\n\n## Service Instances\n\nThe `ibm_resource_instance` resource can be used to create, update or delete any of the offered services by IBM Cloud. You can retrieve list of offered services by installing the `catalogs-management` CLI plug-in and running the `service-marketplace` or `search` subcommands of such plugin.\n\n```bash\nibmcloud plugin install catalogs-management\n\nibmcloud catalog search\n\nibmcloud catalog service-marketplace\nibmcloud catalog service-marketplace | grep message\n\nibmcloud catalog service mqcloud\n```\n\nYou can use the same plugin to create the service however, in this page we'll cover how to manage the service with Terraform, using the resource `ibm_resource_instance`.\n\nThe following table list the most relevant input parameters for the `ibm_resource_instance` resource.\n\n| Input parameter | Description |\n|---|---|\n| `name` | name to identify the resource instance |\n| `service` | name of the service offering |\n| `plan` | name of the plan type supported by service. You can retrieve the value by running the `ibmcloud catalog service <servicename>` command |\n| `location` | target location or environment to create the resource instance |\n| `resource_group_id` | ID of the resource group where you want to create the service. You can retrieve the value from data source `ibm_resource_group`. By default uses the Default resource group |\n| `parameters` | Arbitrary parameters to create instance. The value must be a JSON object |\n\n## Message Queue\n\nIn this section we'll see an example to create a Message & Queue service using the `ibm_resource_instance` resource. Create the file `mq.tf` with the `ibm_resource_instance` resource to create an `mqcloud` service.\n\n```hcl path=mq.rf\nresource \"ibm_resource_instance\" \"resource_instance\" {\n  name              = \"mq-instance-test\"\n  service           = \"mqcloud\"\n  plan              = \"default\"\n  location          = \"us-south\"\n  resource_group_id = data.ibm_resource_group.group.id\n  tags              = [\"message queue\", \"testmq\"]\n\n  timeouts {\n    create = \"15m\"\n    update = \"15m\"\n    delete = \"15m\"\n  }\n}\n```\n\nA simple `main.tf` file to use the above code would be like this:\n\n```hcl path=main.tf\nprovider \"ibm\" {\n  region     = \"us-south\"\n  generation = 2\n}\n\ndata \"ibm_resource_group\" \"group\" {\n  name = \"Default\"\n}\n```\n\nExecute this code with the following terraform commands:\n\n```bash\nterraform init\nterraform plan\nterraform apply\n```\n\nRefer to the [documentation](https://cloud.ibm.com/docs/mqcloud) to know how to use the MQ service from CLI, the Web Console or your own application.\n\n## Final Terraform code\n\nThe only cloud database service used in the complete demo application is MongoDB. You can download the code from the GitHub repository https://github.com/IBM/cloud-enterprise-examples/ in the directory [08_cloud-services](https://github.com/IBM/cloud-enterprise-examples/tree/master/iac/08_cloud-services). This code builds off the compute example by adding the following resources and code.\n\nThe database definition file `db.tf` using the `ibm_database` resource.\n\n```hcl path=db.tf\nresource \"ibm_database\" \"iac_app_db_instance\" {\n  name              = var.db_name\n  plan              = var.db_plan\n  location          = var.region\n  service           = \"databases-for-mongodb\"\n  resource_group_id = data.ibm_resource_group.group.id\n\n  adminpassword                = var.db_admin_password\n  members_memory_allocation_mb = var.db_memory_allocation\n  members_disk_allocation_mb   = var.db_disk_allocation\n}\n```\n\nAppending the new defined variables in the `variables.tf` file.\n\n```hcl path=variables.tf\nvariable \"db_plan\" {\n  default = \"standard\"\n}\nvariable \"db_name\" {\n  default = \"moviedb\"\n}\nvariable \"db_admin_password\" {\n  default = \"inSecureP@55w0rd\"\n}\nvariable \"db_memory_allocation\" {\n  default = \"3072\"\n}\nvariable \"db_disk_allocation\" {\n  default = \"61440\"\n}\n```\n\nThe `compute.tf` file has a new Cloud-Init code in the VSI, like so:\n\n```hcl path=compute.tf\nresource \"ibm_is_instance\" \"iac_app_instance\" {\n  ...\n\n  user_data = <<-EOUD\n            #!/bin/bash\n            mkdir -p /app\n\n            # Application script and dependencies\n            echo '${data.local_file.requirements.content_base64}' | base64 --decode > /app/requirements.txt\n            echo '${data.local_file.app.content_base64}' | base64 --decode > /app/app.py\n            # Script and database to initially import\n            echo '${data.local_file.db.content_base64}' | base64 --decode > /app/db.json\n            echo '${data.local_file.import.content_base64}' | base64 --decode > /app/import.py\n            # Configuration and credentials\n            echo '${ibm_database.iac_app_db_instance.connectionstrings.0.certbase64}' | base64 --decode > /app/db_certificate.cert\n            export PASSWORD=${var.db_admin_password}\n            export APP_MONGODB_URI=\"${ibm_database.iac_app_db_instance.connectionstrings.0.composed}\"\n            export APP_PORT=${var.port}\n\n\n            # https://askubuntu.com/questions/1154892/prevent-question-restart-services-during-package-upgrades-without-asking\n            echo '* libraries/restart-without-asking boolean true' | debconf-set-selections\n\n            # Python3 is installed by default, pip3 is not\n            apt update\n            apt install -y python3-pip\n\n            # Setup and initialize the DB\n            cd /app\n            pip3 install -r requirements.txt\n            python3 import.py\n\n            # Start up the application\n            python3 app.py &\n            EOUD\n\n  ...\n}\n```\n\nIn order to have access to the applications and dependencies file listed below we need to the fine the following terraform data sources with the files content.\n\n```hcl path=app.tf\ndata \"local_file\" \"app\" {\n  filename = \"${path.module}/app/app.py\"\n}\n\ndata \"local_file\" \"import\" {\n  filename = \"${path.module}/app/import.py\"\n}\n\ndata \"local_file\" \"requirements\" {\n  filename = \"${path.module}/app/requirements.txt\"\n}\n\ndata \"local_file\" \"db\" {\n  filename = \"${path.module}/app/db.min.json\"\n}\n```\n\nAnd these files are in the `app/` folder. The `app/app.py` file is the API application using `flask`, `flask-restful` and `flask_mongoengine` packages.\n\n```python path=app/app.py\nfrom flask import Flask, Response, request\nfrom flask_restful import Api, Resource\nfrom flask_mongoengine import MongoEngine\nfrom datetime import datetime\nimport json\nimport os\nimport logging\nimport ssl\n\nlogging.basicConfig(filename='app.log',\n                    level=logging.DEBUG)\nmongodb_uri = os.environ.get('APP_MONGODB_URI')\nif not mongodb_uri:\n    mongodb_uri = 'mongodb://localhost/moviedb'\nport = os.environ.get('APP_PORT')\nif not port:\n    port = '8080'\napp = Flask(__name__)\napp.config['MONGODB_SETTINGS'] = {\n    'MONGODB_HOST': mongodb_uri,\n    'MONGODB_DB': 'moviedb',\n    'MONGODB_SSL': True,\n    'MONGODB_SSL_CERT_REQS': ssl.CERT_REQUIRED,\n    'MONGODB_SSL_CA_CERTS': '/app/db_certificate.cert'\n}\napi = Api(app)\ndb = MongoEngine()\ndb.init_app(app)\n\nclass Movie(db.Document):\n    title = db.StringField(required=True)\n    titleSort = db.StringField()\n    originalTitle = db.StringField()\n    contentRating = db.StringField()\n    rating = db.FloatField()\n    ratingImage = db.StringField()\n    audienceRating = db.FloatField()\n    audienceRatingImage = db.StringField()\n    hasPremiumPrimaryExtra = db.IntField()\n    summary = db.StringField(required=False)\n    year = db.IntField(required=False)\n    tagline = db.StringField()\n    duration = db.IntField(required=False)\n    originallyAvailableAt = db.StringField(required=False)\n    addedAt = db.IntField(\n        default=datetime.timestamp(datetime.now()), required=False)\n    updatedAt = db.IntField(\n        default=datetime.timestamp(datetime.now()), required=False)\n    genre = db.StringField(required=True)\n    # genre = db.ListField(required=True)\n    director = db.ListField(db.StringField(), required=True)\n    writer = db.ListField(db.StringField(), required=False)\n    country = db.StringField(required=False)\n    cast = db.ListField(db.StringField(), required=True)\n\nclass MoviesApi(Resource):\n    def get(self):\n        movies = Movie.objects().to_json()\n        return Response(movies, mimetype=\"application/json\", status=200)\n\n    def post(self):\n        body = request.get_json()\n        movie = Movie(**body).save()\n        id = movie.id\n        return {'id': str(id)}, 200\n\nclass MovieApi(Resource):\n    def put(self, id):\n        body = request.get_json()\n        Movie.objects.get(id=id).update(**body)\n        return '', 200\n\n    def delete(self, id):\n        Movie.objects.get(id=id).delete()\n        return '', 200\n\n    def get(self, id):\n        movie = Movie.objects.get(id=id).to_json()\n        return Response(movie, mimetype=\"application/json\", status=200)\n\napi.add_resource(MoviesApi, '/api/movies')\napi.add_resource(MovieApi, '/api/movies/<id>')\n\n@app.route('/api/healthcheck')\ndef health_check():\n    return {'HealthCheckResponse': True}\n\napp.run(host='0.0.0.0', port=port)\n```\n\nThe `import.py` application is executed before the API application on every instance created, however it only import the JSON db the first time it's executed, so this avoid repeated documents or records. Similar to the simple Python application showed in this page, it uses the `pymongo` package to connect to the DB and insert all the documents.\n\n```python path=app/import.py\nfrom pymongo import MongoClient\nimport json\nimport os\n\nmongodb_uri = os.environ.get('APP_MONGODB_URI')\nif not mongodb_uri:\n    mongodb_uri = 'mongodb://localhost/moviedb'\n\nclient = MongoClient(mongodb_uri,\n                     ssl=True,\n                     ssl_ca_certs=\"/app/db_certificate.cert\")\n\ndbnames = client.list_database_names()\n\nif not 'moviedb' in dbnames:\n    db = client['moviedb']\n    movies = db['movie']\n    with open('./db.json') as f:\n        data = json.load(f)\n    movies.insert_many(data['movies'])\n\nclient.close()\n```\n\nLast but not least, the `requirements.txt` file with the Python packages required for this demo.\n\n```python path=app/requirements.txt\nflask\nflask-restful\nflask-mongoengine\npymongo\n```\n\n## Clean up\n\nFinally, when you finish using the infrastructure for any of the presented examples, cleanup everything you created with the execution of:\n\n```bash\nterraform destroy\n```\n\nIf the example was created with IBM Cloud Schematics, cleanup everything you created with the execution of:\n\n```bash\n\nibmcloud schematics destroy --id $WORKSPACE_ID # Identify the Activity_ID\nibmcloud schematics logs  --id $WORKSPACE_ID --act-id Activity_ID\n\n# ... wait until it's done\n\nibmcloud schematics workspace delete --id $WORKSPACE_ID\nibmcloud schematics workspace list\n```\n","fileAbsolutePath":"/Users/isaias/Documents/Projects/Developer_Advocate_Group/CODE_PATTERNS/ibm-asean-enterprise-cloud-patterns/src/pages/iac-resources/services/index.mdx"}}}}